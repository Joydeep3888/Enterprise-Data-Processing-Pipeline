{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit, year, avg, count, sum\n",
    "import mysql.connector\n",
    "import os\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# AWS Configurations\n",
    "AWS_ACCESS_KEY = \"AKIAIOSFODNN7EXAMPLE\"\n",
    "AWS_SECRET_KEY = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n",
    "S3_BUCKET_NAME = \"joydeep-data-bucket\"\n",
    "RAW_ZONE = \"raw/\"\n",
    "STAGING_ZONE = \"staging/\"\n",
    "\n",
    "# MySQL Database Configuration\n",
    "MYSQL_HOST = \"joydeep-mysql-instance\"\n",
    "MYSQL_DB = \"joydeep_etl_db\"\n",
    "MYSQL_USER = \"joydeep_admin\"\n",
    "MYSQL_PASSWORD = \"JoydeepSecurePass123\"\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ETL Pipeline\").getOrCreate()\n",
    "\n",
    "# Extract Data from CSV\n",
    "def extract_data():\n",
    "    \"\"\"Reads insurance data from CSV file\"\"\"\n",
    "    df = spark.read.csv(r\"C:\\Users\\hp\\OneDrive\\Desktop\\python\\Big_Data\\Cloned\\Project\\insurance_data.csv\", header=True, inferSchema=True)\n",
    "    print(\"Extracted Data:\")\n",
    "    df.show(5)\n",
    "    return df\n",
    "\n",
    "# Transform Data\n",
    "def transform_data(df):\n",
    "    \"\"\"Applies transformations including categorization, risk assessment, and aggregations\"\"\"\n",
    "    df = df.withColumn(\"age_group\", \n",
    "                       when(col(\"age\") < 30, \"Young\")\n",
    "                       .when((col(\"age\") >= 30) & (col(\"age\") < 50), \"Middle-aged\")\n",
    "                       .otherwise(\"Senior\"))\n",
    "    \n",
    "    df = df.withColumn(\"policy_duration\", year(lit(\"2025-01-01\")) - year(col(\"issue_date\")))\n",
    "    \n",
    "    df = df.withColumn(\"risk_score\", \n",
    "                       when(col(\"claim_status\") == \"Approved\", 3)\n",
    "                       .when(col(\"claim_status\") == \"Pending\", 2)\n",
    "                       .when(col(\"claim_status\") == \"Denied\", 1)\n",
    "                       .otherwise(0))\n",
    "    \n",
    "    premium_avg_df = df.groupBy(\"state\").agg(avg(\"premium_amount\").alias(\"avg_premium\"))\n",
    "    claims_count_df = df.groupBy(\"state\").agg(count(\"claim_status\").alias(\"total_claims\"))\n",
    "    total_premium_df = df.groupBy(\"state\").agg(sum(\"premium_amount\").alias(\"total_premium\"))\n",
    "    \n",
    "    df = df.join(premium_avg_df, on=\"state\", how=\"left\")\n",
    "    df = df.join(claims_count_df, on=\"state\", how=\"left\")\n",
    "    df = df.join(total_premium_df, on=\"state\", how=\"left\")\n",
    "    \n",
    "    print(\"Transformed Data:\")\n",
    "    df.show(5)\n",
    "    return df\n",
    "\n",
    "# Load Data into MySQL\n",
    "def load_data(df):\n",
    "    \"\"\"Loads transformed data into MySQL Workbench\"\"\"\n",
    "    connection = mysql.connector.connect(\n",
    "        host=MYSQL_HOST,\n",
    "        user=MYSQL_USER,\n",
    "        password=MYSQL_PASSWORD,\n",
    "        database=MYSQL_DB\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    df_pandas = df.toPandas()\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS processed_insurance_data (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            name VARCHAR(255),\n",
    "            age INT,\n",
    "            state VARCHAR(255),\n",
    "            issue_date DATE,\n",
    "            claim_status VARCHAR(50),\n",
    "            premium_amount FLOAT,\n",
    "            age_group VARCHAR(50),\n",
    "            policy_duration INT,\n",
    "            risk_score INT,\n",
    "            avg_premium FLOAT,\n",
    "            total_claims INT,\n",
    "            total_premium FLOAT\n",
    "        )\"\"\")\n",
    "    \n",
    "    for _, row in df_pandas.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO processed_insurance_data (name, age, state, issue_date, claim_status, premium_amount, age_group, policy_duration, risk_score, avg_premium, total_claims, total_premium)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "    \n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"Data Loaded into MySQL Workbench\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extracted_df = extract_data()\n",
    "    transformed_df = transform_data(extracted_df)\n",
    "    load_data(transformed_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
